{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Emilie Engen, 100356077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Homework #6: Hidden Markov Models for speech processing\n",
    "\n",
    "### A. The three Basic Problems for HMMs\n",
    "\n",
    "For convenience, we use the compact notation \n",
    "\n",
    "$$\\lambda=(A, B,  \\pi)$$\n",
    "\n",
    "to indicate the complete parameter set of the model, where $A$ is the state transition probability distribution, $B$ the emission probability distribution (which can be any distribution with parameters $\\Theta$) and $\\pi$ the initial state distribution.\n",
    "\n",
    "### Problem 1: \n",
    "Given the observation sequence $O=O_1, O_2, ..., O_T$, and a model $\\lambda=(A, B,  \\pi)$, how do efficiently compute $P(O|\\lambda)$?\n",
    "Problem 1 is the evaluation problem, namely given a model and a sequence of observations, how do we compute the probability that the observed sequence was produced by the model. To solve this problem we use the **forward-backward algorithm**.\n",
    "\n",
    "### Problem 2: \n",
    "Given the observation sequence $O=O_1, O_2, ..., O_T$, and a model $\\lambda=(A, B,  \\pi)$, how do we choose a corresponding state sequence $Q= q_1, q_2, ..., q_T$?\n",
    "Problem 2 is the one in which we attempt to uncover the hidden part of the model, that is, the \"correct\" state sequence. A formal technique for finding thes best state sequence is based on dynamic programming methods, and is called **the Viterbi algorithm**.\n",
    "\n",
    "\n",
    "### Problem 3: \n",
    "How do we adjust the model parameters $\\lambda=(A, B,  \\pi)$ to maximize the probability of the observation sequence given the model $P(O|\\lambda)$?\n",
    "There is no known way to analytically solve this problem. We can, however, choose $\\lambda=(A, B,  \\pi)$ such that $P(O|\\lambda)$? is locally maximized using an iterative procedure such as the **the Baum-Welch algoritm** (or equivalently th EM algorithm).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Reference**\n",
    "\n",
    "Lawrence R. Rabiner \"A tutorial on hidden Markov models and selected applications in speech recognition\" Proceedings of the IEEE 77.2, 1989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Problem description\n",
    "\n",
    "The aim of this session is to design a HMM-based speech recogniser.\n",
    "\n",
    "The idea is to design a **word speech recogizer**. For each word of the 7 available words we want to fit a separate N-state HMM. We represent the speech signal of a given word as a **time sequence of coded spectral feature vectors**. For each word, we have a training sequence consisting of 15 repetitions of sequences (by one or more talkers).\n",
    "\n",
    "* The first task is to build individual word models. **This task is done by using the solution to Problem 3** to optimally estimate model parameters for each word model.\n",
    "\n",
    "* **To understand the physical meaning of the model states, we use the solution to Problem 2** to divide each of the word training sequences into states, and then study the properties of the spectral vectors that lead to the observation ocurring in each state.\n",
    "\n",
    "* Finally, once the set of 7 HMMs has been fitted and optimized , **recognition of unknown word is performed using the solution of Problem 1**.\n",
    "\n",
    "The file ``words_db.pickle`` contains 15 instances of 7 different words. ``words_db['signals']`` contains the audio signals at a sampling frequency of 8 KHz, ``words_db['features']`` contains a 6 dimensions frequency feature sequences extracted from the audio signals, and ``words_db['word_labels']`` contains the transcription of the words. \n",
    "\n",
    "Depending on the computer hardware specifications, the signals can be reproduced using the package ``audiolab`` from ``scikits``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word sequences modeling\n",
    "\n",
    "\n",
    "* Load the file and select the instances of the word ``apple``\n",
    "* Divide the instances of the word ``apple`` into train (5) and test (10)\n",
    "* Train a HMM with Gaussian emission probability and 3 hidden states using the train sequences and evaluate the loglikelihood on the test sequences\n",
    "* Plot the loglikelihood on the test sequences using a number of hidden states from 1 to 10 and comment the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word classifier\n",
    "\n",
    "We will now train a different HMM for each word, and the output of the classifier will be the word with higher loglikelihood.\n",
    "* Divide the instances of each word into train (5) and test (10)\n",
    "* Train the HMM's and estimate the classification error on the test instances. Print out the confusion matrix.\n",
    "* Use LOO onto the train instances to select the number of hidden states. Try values from 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"default\")\n",
    "\n",
    "# Load the file\n",
    "with open('words_db.pickle','rb') as handle:\n",
    "    words_db = pickle.load(handle,encoding='latin1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'kiwi', 'peach', 'apple', 'pineapple', 'lime', 'orange']\n"
     ]
    }
   ],
   "source": [
    "# Signals\n",
    "signals=words_db['signals']\n",
    "\n",
    "# Features\n",
    "features=words_db['features']\n",
    "\n",
    "# Words labels\n",
    "labels=words_db['labels']\n",
    "\n",
    "# Print the different words\n",
    "words=list(set(labels))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of a given targetword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_idx(allwords,targetword):\n",
    "    idx=np.array([i for i,x in enumerate(allwords) if x==targetword])\n",
    "    orden=np.arange(idx.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the indices for the word ``apple``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  7 10  0  8  4  6  5 11  9  3 14 13 12  2]\n"
     ]
    }
   ],
   "source": [
    "idx=word_idx(labels,'apple')\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word sequences modeling\n",
    "\n",
    "Define functions for getting train and test sets for a given word and for fitting a Gaussian HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train and test sets and their respective sequence lengths\n",
    "def getTrainTestSets(features,idx):\n",
    "    # idx is the index vector identifying a given word\n",
    "    numsq_train=5 # Number of sequences in training set\n",
    "    numsq_test=10 # Number of sequences in test set\n",
    "    # Notice that I had to include dtype int to make the array of integer type\n",
    "    seqlenght_train = np.empty(numsq_train,dtype=np.int) # Sequence length train set\n",
    "    x_train = np.empty([0,6])\n",
    "    \n",
    "    for i in range(numsq_train):\n",
    "        x_train = np.append(x_train,np.transpose(features[idx[i]]),axis=0)\n",
    "        seqlenght_train[i] = int(features[idx[i]].shape[1])\n",
    "    \n",
    "    seqlenght_test = np.empty(numsq_test,dtype=np.int) # Sequence length test set\n",
    "    x_test = np.empty([0,6])\n",
    "    \n",
    "    for i in range(numsq_train,15):\n",
    "        x_test = np.append(x_test,np.transpose(features[idx[i]]),axis=0)\n",
    "        seqlenght_test[i-numsq_train] = int(features[idx[i]].shape[1])\n",
    "    \n",
    "    return x_train,seqlenght_train,x_test,seqlenght_test\n",
    "\n",
    "# Fit a Gaussian HMM model and evaluate the log likelihood\n",
    "np.random.seed(0)\n",
    "def fitGaussianHMM(x_train,seqlenght_train,x_test,seqlenght_test,n_components):\n",
    "    model = GaussianHMM(n_components=n_components,covariance_type=\"full\",n_iter=1000).fit(x_train,seqlenght_train)\n",
    "    ll = model.score(x_test,seqlenght_test)\n",
    "    return ll,model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the instances of the word ``apple`` into train (5) and test (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = word_idx(labels,'apple')\n",
    "x_train,seqlenght_train,x_test,seqlenght_test = getTrainTestSets(features,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a HMM with Gaussian emission probability and 3 hidden states using the train sequences and evaluate the loglikelihood on the test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log likelihood for the model is -25295.624508047393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "ll,model = fitGaussianHMM(x_train,seqlenght_train,x_test,seqlenght_test,3)\n",
    "print('The log likelihood for the model is {}'.format(ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loglikelihood on the test sequences using a number of hidden states from 1 to 10 and comment the obtained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:459: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:468: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:460: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:469: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:624: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n"
     ]
    }
   ],
   "source": [
    "lls = np.empty([0,1])\n",
    "idxs = np.empty([0,1])\n",
    "for i in range(1,11):\n",
    "    ll,model = fitGaussianHMM(x_train,seqlenght_train,x_test,seqlenght_test,i)\n",
    "    lls = np.append(lls,ll)\n",
    "    idxs = np.append(idxs,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log likelihood for the model with 1 hidden states is -25581.335211801408\n",
      "The log likelihood for the model with 2 hidden states is -25248.40134585355\n",
      "The log likelihood for the model with 3 hidden states is -25295.624508047327\n",
      "The log likelihood for the model with 4 hidden states is -25245.363411045142\n",
      "The log likelihood for the model with 5 hidden states is -25336.251371875715\n",
      "The log likelihood for the model with 6 hidden states is -25380.402351435027\n",
      "The log likelihood for the model with 7 hidden states is -25578.079855052943\n",
      "The log likelihood for the model with 8 hidden states is -25725.905983004308\n",
      "The log likelihood for the model with 9 hidden states is -25838.230924524636\n",
      "The log likelihood for the model with 10 hidden states is -26303.056826721404\n"
     ]
    }
   ],
   "source": [
    "# Print the log likelihood for each number of hidden states\n",
    "for i in range (len(lls)):\n",
    "    print('The log likelihood for the model with {} hidden states is {}'.format(i+1,lls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiL1pvAQEZF6+/+XngSxWTNMXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ac69e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the log likelihood values\n",
    "plt.plot(idxs,lls,'-.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word classifier\n",
    "\n",
    "We will now train a different HMM for each word, and the output of the classifier will be the word with higher loglikelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Divide the instances of each word into train (5) and test (10)\n",
    "* Train the HMM's and estimate the classification error on the test instances. Print out the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:459: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:468: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:460: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:469: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:624: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Train a Gaussian HMM for each word\n",
    "models=[]\n",
    "for word in words:\n",
    "    idx = word_idx(labels,word)\n",
    "    x_train,seqlenght_train,x_test,seqlenght_test = getTrainTestSets(features,idx)\n",
    "    ll,model = fitGaussianHMM(x_train,seqlenght_train,x_test,seqlenght_test,4)\n",
    "    models=np.append(models,model)\n",
    "\n",
    "# Log likelihood matrix\n",
    "lls=np.zeros((105,7)) \n",
    "\n",
    "# Get log likelihood for every word in data set\n",
    "for i in range(7):\n",
    "    m=models[i]\n",
    "    for j in range(105):            \n",
    "        x=features[j].T\n",
    "        lls[j,i]=np.round(m.score(x))\n",
    "\n",
    "\n",
    "# Get label with highest log likelihood\n",
    "def getlabels(lls,words):\n",
    "    n,k = lls.shape\n",
    "    label_pred = []\n",
    "    j=1\n",
    "    for i in range(n):\n",
    "        aux=np.nonzero(lls[i,:]==lls[i,:].max())\n",
    "        label_pred.append(words[int(aux[0][0])])\n",
    "        \n",
    "    label_pred = np.asarray(label_pred)\n",
    "    return label_pred\n",
    "\n",
    "label_pred = getlabels(lls,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      apple       1.00      1.00      1.00        15\n",
      "     banana       1.00      1.00      1.00        15\n",
      "       kiwi       1.00      0.93      0.97        15\n",
      "       lime       1.00      0.80      0.89        15\n",
      "     orange       1.00      1.00      1.00        15\n",
      "      peach       0.94      1.00      0.97        15\n",
      "  pineapple       0.83      1.00      0.91        15\n",
      "\n",
      "avg / total       0.97      0.96      0.96       105\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[15  0  0  0  0  0  0]\n",
      " [ 0 15  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  1  0]\n",
      " [ 0  0  0 12  0  0  3]\n",
      " [ 0  0  0  0 15  0  0]\n",
      " [ 0  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  0 15]]\n",
      "\n",
      "Classification error: 3.81 percent\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print('Classification report:')\n",
    "print(classification_report(labels, label_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels,label_pred)\n",
    "print('\\nConfusion matrix:\\n',cm)\n",
    "\n",
    "# Classification error\n",
    "missed = (label_pred != labels)\n",
    "print('\\nClassification error: %.2f percent' % (100 * (np.mean(missed))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LOO onto the train instances to select the number of hidden states. Try values from 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Concatenate the elements of X\n",
    "def concatenateFeatureMatrix(X):\n",
    "    seqlenght = np.empty(len(X),dtype=np.int)\n",
    "    sequences = np.empty([0,6])\n",
    "    for i in range(X.shape[0]):\n",
    "        sequences = np.append(sequences,np.transpose(X[i]),axis=0)\n",
    "        seqlenght[i] = int(X[i].shape[1])\n",
    "    return sequences,seqlenght\n",
    "\n",
    "# Use LOO to get log likelihood for a certain number of hidden states\n",
    "def getLLForHiddenState(X,hidden_states):\n",
    "    models=[]\n",
    "    ll=[] \n",
    "    kf = KFold(n_splits=15)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        sequences,seqlenght = concatenateFeatureMatrix(X[train_index]) # Concatenate the elements in the train set\n",
    "        model = GaussianHMM(n_components=hidden_states,covariance_type='full',n_iter=100).fit(\n",
    "        sequences,lengths=seqlenght) # Fit the Gaussian HMM for a given number of hidden states\n",
    "        ll=np.append(ll,model.score(X[test_index][0].T))\n",
    "    return ll.mean() # Get the average log likelihood value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:459: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:468: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of hidden states for banana is 5\n",
      "The optimal number of hidden states for kiwi is 4\n",
      "The optimal number of hidden states for peach is 5\n",
      "The optimal number of hidden states for apple is 5\n",
      "The optimal number of hidden states for pineapple is 4\n",
      "The optimal number of hidden states for lime is 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:460: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:469: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/Users/Emilie/anaconda/envs/py3.2/lib/python3.6/site-packages/hmmlearn-0.2.0-py3.6-macosx-10.7-x86_64.egg/hmmlearn/base.py:624: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of hidden states for orange is 5\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal number of hidden states for each HMM\n",
    "for word in words:\n",
    "    idx=word_idx(labels,word)\n",
    "    X=features[idx]\n",
    "    lls=[]\n",
    "    hidden_states=[1,2,3,4,5]\n",
    "    for hs in hidden_states:\n",
    "        ll=getLLForHiddenState(X,hs)\n",
    "        lls.append(ll)\n",
    "    opt_hs=hidden_states[np.argmax(lls)]\n",
    "    print('The optimal number of hidden states for {} is {}'.format(word,opt_hs))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3.2]",
   "language": "python",
   "name": "conda-env-py3.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
