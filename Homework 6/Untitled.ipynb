{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"default\")\n",
    "\n",
    "with open('words_db.pickle', 'rb') as handle:\n",
    "    words_db = pickle.load(handle, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lime', 'pineapple', 'orange', 'apple', 'kiwi', 'peach', 'banana']\n"
     ]
    }
   ],
   "source": [
    "# signals\n",
    "signals=words_db['signals']\n",
    "# features\n",
    "features=words_db['features']\n",
    "# words labels\n",
    "labels=words_db['labels']\n",
    "#print the different words\n",
    "words = list(set(labels))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_idx(allwords, targetword):\n",
    "    idx=np.array([i for i,x in enumerate(allwords) if x==targetword])\n",
    "    orden=np.arange(idx.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  9 14  5  1  7  8  4 10  2  0 11 13  6 12]\n"
     ]
    }
   ],
   "source": [
    "idx = word_idx(labels,'apple')\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrainTestSets(features,idx):\n",
    "    #idx is the index vector identifying a given word\n",
    "\n",
    "    numsq_train=5 # number of sequences in training set\n",
    "    numsq_test=10 # number of sequences in test set\n",
    "    seqlenght_train = np.empty(numsq_train) # sequence length\n",
    "    x_train = np.empty([0,6])\n",
    "    \n",
    "    for i in range(numsq_train):\n",
    "        x_train = np.append(x_train,np.transpose(features[idx[i]]),axis=0)\n",
    "        seqlenght_train[i] = int(str(features[idx[i]].shape[1]).rstrip('.0'))\n",
    "        \n",
    "\n",
    "    seqlenght_test = np.empty(numsq_test)\n",
    "    x_test = np.empty([0,6])\n",
    "    y_test = np.empty([0,1])\n",
    "    \n",
    "    for i in range(numsq_train,15):\n",
    "        x_test = np.append(x_test,np.transpose(features[idx[i]]),axis=0)\n",
    "        seqlenght_test[i-numsq_train] = int(features[idx[i]].shape[1])\n",
    "        y_test = np.append(y_test,labels[idx[i]])\n",
    "\n",
    "    return x_train,seqlenght_train,x_test,seqlenght_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.  59.  53.  56.  48.]\n"
     ]
    }
   ],
   "source": [
    "idx = word_idx(labels,'apple')\n",
    "Xtrain,lenTrain,Xtest,lenTest,yTest = getTrainTestSets(features,idx)\n",
    "print(lenTrain)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3.2]",
   "language": "python",
   "name": "conda-env-py3.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
