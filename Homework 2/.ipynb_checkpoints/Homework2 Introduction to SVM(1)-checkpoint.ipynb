{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Abdelmalik Moujahid -- abdelmalik.moujahid@uc3m.es\n",
    "\n",
    "Date: February 15, 2017\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "## Session #2: Linear and Nonlinear SVM\n",
    "\n",
    "The aim of this session is to get familiar with the SVM implementation of scikit-learn. \n",
    "The documentation can be found at <a href = http://scikit-learn.org/stable/modules/svm.html>  scikit-learn.org/stable/modules/svm.html</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages and some useful functions:\n",
    "\n",
    "    * import numpy as np (np.random.randn, np.r_, np.linespace, np.logspace, np.logical_xor)\n",
    "    * import matplotlib.pyplot as plt (plt.plot, plt.scatter, plt.show(), plt.semilogx)\n",
    "    * from sklearn import svm, cross_validation (svm.SVC(), cross_validation.train_test_split)\n",
    "    \n",
    "    \n",
    "\n",
    "The iPython Notebook should be sent using the assignment activity module (See Aula Global). The deadline for submitting your reports ends on **February 22**. **The iPython Notebook should indicate your names and your email address**. \n",
    "\n",
    "\n",
    "**The deadline is extended to February 24.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear SVM\n",
    "\n",
    "a) Generate a two-dimensional linearly separable dataset with 300 samples. We consider a two-class balanced classification problem. The samples from the first class are normally distributed with $\\mu=0$ and $\\sigma=1.5$, while the samples from the second class have $\\mu=3$ and $\\sigma=1.5$. \n",
    "\n",
    "    * Use a Scatter plot to show the data in a two-dimensional space and give a different color to each class. \n",
    "    \n",
    "b) Fit a linear SVC using part of the data in X as training set (X_train, y_train) and holding out part of the available data as a test set (X_test, y_test). \n",
    "\n",
    "c) Get and plot the separating hyperplane and the parallels to the separating hyperplane that pass through the support vectors. How about the number of support vectors?\n",
    "\n",
    "d) Compute the classification scores both on training and test sets.\n",
    "\n",
    "e) Fit the model for different values of the penalty parameter C (from very low values to very high ones). Study the influence of this parameter on the classification score and on the number of support vectors. Why the margin is larger for low values of C than it is for higher values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below you have some expected results\n",
    "\n",
    "* For a better visualization, the number of samples in the dataset has been reduced to 100 samples (50 from class1 and 50 from class two). The training set has 80 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](linearlyData.png)\n",
    "![](svcLinearlyData_c1.png)\n",
    "![](svcLinearlyData_c2.png)\n",
    "![](linearSVCperformance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Nonlinear SVM\n",
    "\n",
    "a) Generate a two-dimensional non-linearly separable dataset with 300 samples. For that, start from a two-dimensional array (X) of normally distributed data and get a target vector (y) using the logical XOR operator. \n",
    "\n",
    "b) Visualize the data using a scatter plot and give a different color to each class. \n",
    "\n",
    "c) Fit a RBF kernel SVC using the default parameters. Plot the decision function for each datapoint (you can take as baseline the function plot_svm_nonlinear.py from <a href = http://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html> scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html</a>)\n",
    "\n",
    "d) Study how the kernel parameter $\\gamma$ and the penalty parameter C affect the shape of the decision function. Tune these parameters to obtain:\n",
    "    * A decision boundary almost linear\n",
    "    * A very sharp decision boundary\n",
    "    * A curved, smooth decision boundary\n",
    "    \n",
    "e) Fit a Polynomial kernel SVC with degreees 1, 2, 3, 4. Interprete the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3.2]",
   "language": "python",
   "name": "conda-env-py3.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
